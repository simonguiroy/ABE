{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute the aggregated moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_m1_hat(h_vectors_):\n",
    "  \"\"\"\n",
    "  Computes the first raw moment (sample mean) of first-order moments.\n",
    "  First-order moments are the (sample) means of the individual activation features.\n",
    "  For a matrix H \\in R^{N \\times d} of N activation vectors h, where h \\in R^d :\n",
    "  m1_hat = \\frac{1}{d} \\sum_{j=1}^{d} \\frac{1}{N} \\sum{i=1}^{N} H_{i,j}\n",
    "  :param h_vectors_: the activation vectors\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  H = h_vectors_.view(size=[h_vectors_.shape[0], -1])\n",
    "  N = H.shape[0]\n",
    "  d = H.shape[1]\n",
    "\n",
    "  # First-order moment of the activation vectors : mean vector\n",
    "  m1 = torch.mean(H, dim=0)\n",
    "\n",
    "  # m1_hat : first aggregated moment - first-order moment across feature dimensions of the mean activation vector\n",
    "  m1_hat = torch.mean(m1)\n",
    "\n",
    "  return m1_hat\n",
    "\n",
    "def compute_m2_hat(h_vectors_):\n",
    "  \"\"\"\n",
    "  Computes the second raw moment (sample variance aroud zero) of first-order moments.\n",
    "  First-order moments are the (sample) means of the individual activation features.\n",
    "  For a matrix H \\in R^{N \\times d} of N activation vectors h, where h \\in R^d :\n",
    "  m2_hat = \\frac{1}{d} \\sum_{j=1}^{d} ( \\frac{1}{N} \\sum{i=1}^{N} H_{i,j} )^2\n",
    "  :param h_vectors_: the activation vectors\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  H = h_vectors_.view(size=[h_vectors_.shape[0], -1])\n",
    "  N = H.shape[0]\n",
    "  d = H.shape[1]\n",
    "\n",
    "  # First-order moment of the activation vectors : mean vector\n",
    "  m1 = torch.mean(H, dim=0)\n",
    "\n",
    "  # m2_hat : second aggregated moment - second-order moment across feature dimensions of the mean activation vector    \n",
    "  m2_hat = torch.mean(m1 ** 2)  \n",
    "\n",
    "  return m2_hat\n",
    "\n",
    "def compute_m3_hat(h_vectors_):\n",
    "  \"\"\"\n",
    "  Computes the first raw moment (sample mean) of the diagonal elements of the matrix of second-order moments (auto-correlation matrix).\n",
    "  Diagonal second-order moments are the (sample) variances of the individual activation features.\n",
    "  For a matrix H \\in R^{N \\times d} of N activation vectors h, where h \\in R^d :\n",
    "  m3_hat = \\frac{1}{d} \\sum_{j=1}^{d} \\frac{1}{N} \\sum{i=1}^{N} H_{i,j}^2\n",
    "  :param h_vectors_: the activation vectors\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  H = h_vectors_.view(size=[h_vectors_.shape[0], -1])\n",
    "  N = H.shape[0]\n",
    "  d = H.shape[1]\n",
    "    \n",
    "  # m3_hat : third aggregated moment - first-order moment across feature dimensions of the diagonal elements of the auto-correlation matrix\n",
    "  m2_diag = torch.mean(H ** 2, dim=0)\n",
    "  m3_hat = torch.mean(m2_diag)\n",
    "    \n",
    "  return m3_hat\n",
    "\n",
    "def compute_m4_hat(h_vectors_, max_block_size=500):\n",
    "  \"\"\"\n",
    "  Computes the first raw moment (sample mean) of the non-diagonal elements of the matrix of second-order moments.\n",
    "  Non-diagonal second-order moments are the (sample) covariances of the individual activation features.\n",
    "  For a matrix H \\in R^{N \\times d} of N activation vectors h, where h \\in R^d :\n",
    "  m4_hat = \\frac{1}{d^2 - d} \\sum_{k=1}^{d} \\sum_{j=1, j \\neq k}^{d} \\frac{1}{N} \\sum{i=1}^{N} H_{i,j} \\time H_{i,k}\n",
    "  :param h_vectors_: the activation vectors\n",
    "  :param max_block_size: size of smaller blocks to break the matrix multiplication for the covariances\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  H = h_vectors_.view(size=[h_vectors_.shape[0], -1])\n",
    "  N = H.shape[0]\n",
    "  d = H.shape[1]\n",
    "\n",
    "  m4_hat = 0.0\n",
    "  num_blocks = d / max_block_size\n",
    "  for i in range(np.int(np.floor(num_blocks))):\n",
    "    B = H[:, i * max_block_size:(i + 1) * max_block_size]\n",
    "    m4_hat = m4_hat + torch.sum(torch.matmul(torch.transpose(B, 0, 1), B))\n",
    "  if num_blocks % 1 > 0:\n",
    "    B = H[:, np.int(np.floor(num_blocks)) * max_block_size:]\n",
    "    m4_hat = m4_hat + torch.sum(torch.matmul(torch.transpose(B, 0, 1), B))\n",
    "  m4_hat = m4_hat - torch.sum(H ** 2)\n",
    "  m4_hat = m4_hat / (N * (d * (d - 1)))\n",
    "\n",
    "  return m4_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function of ABE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABE_objective(traj_target, traj_source, t1, t2):\n",
    "    \"\"\"\n",
    "    The objective of ABE. Corresponds to Equation 4 (page 5) of https://arxiv.org/abs/2208.02377\n",
    "    \"\"\"\n",
    "    if t2 - t1 > 0:\n",
    "        corr, _ = scipy.stats.pearsonr(traj_target[t1:t2], traj_source[t1:t2])\n",
    "        # The score is the product of the negative (Pearson) correlation and the width of the time interval\n",
    "        score = - (corr * (t2 - t1 + 1))\n",
    "    else :\n",
    "        score = 0.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the critical time by miximizing the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_time(task_idx, critical_layer_idx, critical_moment_idx, moments_target, moments_target_iters, moments_source, acc_valid, iters_valid):\n",
    "    \"\"\"\n",
    "    Computes the critical time, and the associated objective value, for a pair of target and source trajectories.\n",
    "    The critical time simply corresponds to the iteration where the objective is maximal, within the interval [t0, t*_valid]\n",
    "    \"\"\"\n",
    "    # t2 is the iteration of t*_valid (or the end of the experiment)\n",
    "    max_length = np.min([len(moments_target[critical_moment_idx, :, task_idx, critical_layer_idx]),\n",
    "                             len(moments_source[critical_moment_idx, :, critical_layer_idx])])\n",
    "    limit = np.argmin(np.abs(moments_target_iters - iters_valid[np.argmax(acc_valid)])) + 1\n",
    "    limit = np.min([limit, max_length])\n",
    "    max_length = limit\n",
    "    t2 = max_length\n",
    "    \n",
    "    traj_target = moments_target[critical_moment_idx, :, task_idx, critical_layer_idx]\n",
    "    traj_source = moments_source[critical_moment_idx, :, critical_layer_idx]\n",
    "    \n",
    "    max_score = - np.infty\n",
    "    critical_time_ = 0\n",
    "    t0 = 0\n",
    "    for t in range(t0, t2):\n",
    "        t1 = t\n",
    "        score = ABE_objective(traj_target, traj_source, t1, t2)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            critical_time_ = t1\n",
    "            \n",
    "    return critical_time_, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
